# Multi-Armed Bandit Problem

This repository contains Python code to simulate and compare different algorithms for solving the Multi-Armed Bandit problem.

## Algorithms Implemented
- Greedy
- Epsilon-Greedy
- UCB (Upper Confidence Bound)
- Random
- Boltzmann
- Bayesian

## Usage
1. Clone the repository.
2. Ensure you have Python installed on your system.
3. Run the `multi_armed_bandit.py` script.
4. View the generated plots to compare the performance of different algorithms.

## Results
The results of each algorithm are plotted to show the cumulative rewards over episodes. These plots help in comparing the effectiveness of each algorithm in solving the Multi-Armed Bandit problem.

![Reward-ActionSelection](https://github.com/ParisaMohammadi9094/MultiArmed_Bandit-ActionSelection/assets/18152407/cce74e2e-5d05-4f6b-a87e-2fa580e3298d)

## References
- Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction (2nd ed.). MIT Press.
- Riquelme, C., Tucker, G., & Snoek, J. (2018). Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling. International Conference on Learning Representations.
